# ğŸ¤– Prompt-Optimized Chat Assistant

A hands-on demonstration of advanced prompt engineering techniques with Large Language Models (LLMs). This project showcases how strategically designed prompts can dramatically improve the quality, reliability, and reasoning capabilities of AI responses.

## ğŸ¯

"I built a prompt engineering demo that compares three prompting techniques - zero-shot, few-shot, and chain-of-thought - showing how strategic prompt design significantly improves LLM output quality and reasoning capabilities."

## ğŸ“ What It Does - Simple Explanation

### Zero-Shot Prompting
**Input**: Just the question without examples
**Output**: Model tries to answer based on its general knowledge


**Built a prompt engineering demo to showcase:**
- **Zero-shot prompting** â€“ Model answers without examples using only instructions
- **Few-shot prompting** â€“ Model learns from in-context examples before answering  
- **Chain-of-thought (CoT) prompting** â€“ Model explains reasoning step-by-step for complex problems

Input:
"Text: 'Weather is okay' â†’ Neutral
Text: 'This is amazing!' â†’ Positive
Text: 'I hate traffic' â†’ Negative
Text: 'Package arrived early' 

**Demonstrated Skills:**
- âœ… **Prompt Design & Engineering** â€“ Crafting effective instructions for LLMs
- âœ… **Context Injection** â€“ Providing relevant examples and constraints
- âœ… **Reasoning Control** â€“ Guiding model thought processes for accurate results
- âœ… **LLM Integration** â€“ Working with local and cloud-based language models
- âœ… **Output Quality Optimization** â€“ Using prompt techniques to improve response quality

## ğŸš€ Overview

Different prompting strategies yield dramatically different results from LLMs. This project implements and compares three fundamental techniques:

- **Zero-Shot Prompting**: Direct instructions without examples
- **Few-Shot Prompting**: Learning from demonstration examples  
- **Chain-of-Thought Prompting**: Step-by-step reasoning guidance

## ğŸ› ï¸ Technical Implementation

### Architecture
```

prompt-engineering-demo/
â”‚
â”œâ”€â”€ prompts/ # Prompt templates demonstrating each technique
â”‚ â”œâ”€â”€ zero_shot.txt # Direct instruction-based prompts
â”‚ â”œâ”€â”€ few_shot.txt # Example-driven prompts
â”‚ â””â”€â”€ chain_of_thought.txt # Step-by-step reasoning prompts
â”‚
â”œâ”€â”€ app.py # Main application with interactive demo
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # Project documentation
```

Local LLM with Ollama

```
# 1. Install Ollama from https://ollama.ai/

# 2. Pull a model (in separate terminal)
ollama pull llama3.2:1b

# 3. Start Ollama service (keep this running)
ollama serve

# 4. Set up Python environment
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install requests

# 5. Run the application
python app.py
```